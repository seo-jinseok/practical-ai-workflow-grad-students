# Week 16: 데이터 분석 시연
## MCP 서버 + AI 코드 생성

### 시연 개요 (30초)

**강사 멘트**: "Week 16, 데이터 분석 단계입니다.
Part 2의 MCP 서버와 Part 3의 AI 도구들이 어떻게 통합되는지 확인해보겠습니다.
Python 코드 자동 생성부터 통계 분석까지 보여드리겠습니다."

**강의실 설정**:
- jupyter-mcp 실행 준비
- Copilot 워크북 Exercise 3 결과
- 타이머: 1분

### Step 1: Copilot 워크북 Exercise 3 결과 (30초)

#### Python 코드 생성 (15초)

**강사 액션**:
1. `05-copilot-workbook/` 폴더로 이동
2. Python 파일 열기: `data-analysis.py`

**강의실 화면 표시**:
```python
# 온라인 학습 참여도 데이터 분석
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# 데이터 로드
df = pd.read_csv('online_learning_survey.csv')

# 기술통계
print("=== 기술통계 ===")
print(df.describe())

# 상관관계 분석
correlation = df[['engagement', 'motivation', 'self_regulation']].corr()
print("\n=== 상관관계 ===")
print(correlation)

# 회귀분석
from sklearn.linear_model import LinearRegression
model = LinearRegression()
X = df[['motivation', 'self_regulation']]
y = df['engagement']
model.fit(X, y)
```

**강사 멘트**: "Copilot 워크북 Exercise 3로 생성한 Python 코드입니다. 데이터 분석의 기본 구조를 자동으로 생성했습니다."

#### 결과 해석 템플릿 (15초)

**강사 액션**:
1. 분석 결과 템플릿 파일 열기
2. 완성된 해석 표시

**강의실 화면 표시**:
```markdown
## 데이터 분석 결과

### 기술통계
- 평균 참여도: 3.45 (5점 척도)
- 표준편차: 0.78
- 참여도 분포: 정규분포 close

### 상관관계 분석
- 참여도 vs 동기: r = 0.72 (p < 0.001)
- 참여도 vs 자기조절: r = 0.68 (p < 0.001)
- 동기 vs 자기조절: r = 0.65 (p < 0.001)

### 회귀분석 결과
- R² = 0.58 (58% 설명력)
- 동기계수: β = 0.42 (p < 0.001)
- 자기조절계수: β = 0.36 (p < 0.001)
```

### Step 2: jupyter-mcp 통합 (30초)

#### 코드 실행 및 결과 (15초)

**강사 액션**:
1. jupyter-mcp로 코드 실행
2. 실제 결과 표시

**강의실 화면 표시**:
```python
# 실행 결과
=== 기술통jska ===
engagement    3.45  0.78
motivation    3.67  0.82
self_regulation 3.23  0.91

=== 상관관계 ===
            engagement  motivation  self_regulation
engagement        1.00        0.72           0.68
motivation        0.72        1.00           0.65
self_regulation   0.68        0.65           1.00

=== 회귀분석 ===
R² = 0.58
회귀식: 참여도 = 0.42*동기 + 0.36*자기조절 + ε
```

**강사 멘트**: "jupyter-mcp로 코드를 실행했습니다. 모든 결과가 올바르게 계산되었습니다."

#### 시각화 생성 (15초)

**강사 액션**:
1. 차트 생성 코드 실행
2. 생성된 그래프 표시

**강의실 화면 표시**:
- 상관관계 히트맵
- 참여도 분포 히스토그램
- 회귀분석 산점도

**강사 멘트**: "Python 시각화로 연구 결과를 직관적으로 표현했습니다. AI가 자동 생성한 코드입니다."

### Step 3: 정성적 데이터 분석 (15초)

#### NVivo + AI 통합 (15초)

**강사 멘트**: "정성적 데이터는 NVivo에서 코딩하고, AI로 패턴을 분석했습니다."

**강의실 화면 표시**:
```
정성적 분석 결과 (NVivo + AI):

주제 1: 동기 요인
- "학습 목표가 명확할 때 더 적극적이었습니다" (8명)
- "성취감 때문에 계속 참여했습니다" (6명)
- AI 분석: 동기 부재가 참여도 저하의 주요 원인

주제 2: 환경 요인
- "깅강적인 인터넷 연결이 방해가 되었습니다" (5명)
- "집중할 수 있는 공간이 필요합니다" (7명)
- AI 분석: 기술적·물리적 환경의 중요성

주제 3: 상호작용 요인
- "동료와의 토론이 도움이 되었습니다" (9명)
- "교수의 피드백이 필요합니다" (8명)
- AI 분석: 사회적 상호작용이 핵심 요인
```

### Step 4: 통합 결과 (15초)

#### 정량·정성 결과 비교 (15초)

**강사 멘트**: "정량과 정성 분석 결과를 통합했습니다."

**강의실 화면 표시**:
```
통합 분석 결과:

일치하는 부분:
✓ 동기가 참여도에 가장 큰 영향 (r=0.72, 8명 언급)
✓ 자기조절의 중요성 (r=0.68, 6명 언급)
✓ 환경 요인의 영향 (기술적·물리적)

보완적인 부분:
✓ 정량: 환경 요인 직접 측정 부족
✓ 정성: 구체적 환경 개선 방안 제시

통합 해석:
학습 동기 + 자기조절능력 + 최적의 환경 = 높은 참여도
```

**강사 멘트**: "Part 1-2-3의 모든 도구가 하나의 분석 결과로 통합되었습니다. 이것이 진짜 AI 협업입니다."

### 시연 후 제공할 자료

1. **data-analysis.py**: Copilot으로 생성한 분석 코드
2. **jupyter-notebook.ipynb**: 실행된 노트북
3. **정성적 분석 보고서**: NVivo + AI 결과
4. **통합 분석 결과**: 정량·정성 비교

### 시연 중 점검 질문

**강사 멘트**: "확인해보겠습니다:
- AI가 생성한 코드가 올바른가요?
- 정량·정성 결과가 상호 보완적인가요?
- 전체적인 연구 품질이 향상되었나요?"

### 다음 단계 연결 (15초)

**강사 멘트**: "Week 16 데이터 분석 완료 후, Week 17-20에는 심화 분석이 필요합니다.
하지만 오늘은 이 정도에서 마무리하고, Week 24 논문 작성으로 넘어가겠습니다."

**강의실 화면 표시**:
```
Week 17-20: 심화 분석
- 통계적 유의성 검증
- 주제별 심층 분석
- 통합 결과 해석
- 학술적 Discuss작성

Week 21-24: 논문 작성
- Copilot 워크북 Exercise 4
- 4단계 검증 프로세스
- 최종 논문 완성
```

### 시연 성공 지표

**강사’가 확인할 것**:
- [ ] AI 코드 생성의 정확성
- [ ] MCP 서버 통합의 원활성
- [ ] 정량·정성 분석의 상호 보완성
- [ ] 전체 연구 품질의 향상

**학생들이 얻을 것**:
- AI 활용 데이터 분석 실전 기법
- MCP 서버의 실용성 체감
- 정량·정성 혼합 분석의 효과
- AI와 인간의 협업 방식

---

**시연 팁**: jupyter-mcp가 작동하지 않으면 Copilot이 생성한 코드만 보여주고, "실제 사용에서는 실행 환경이 필요합니다" 설명하기.
